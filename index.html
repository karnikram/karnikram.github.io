<html>

<head>
	<meta name="generator" content="Hugo 0.54.0" />

	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-108865845-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag() { dataLayer.push(arguments); }
		gtag('js', new Date());

		gtag('config', 'UA-108865845-1');
	</script>

	<meta name="robot" content="index,imageindex">
	<style type="text/css">
		a {
			color: #072140;
			text-decoration: none;
			font-weight: bold;
		}

		a:focus,
		a:hover {
			color: #3070B3;
			text-decoration: none;
		}

		body,
		td,
		th,
		tr,
		p {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 14px;
			color: #072140;
			background-color: #fefefe;
		}

		strong {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 14px;
		}

		heading {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 22px;
			color: #3070B3;
			font-weight: 300;
		}

		papertitle {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 14px;
			color: #3070B3;
		}

		name {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 32px;
			color: #3070B3;
			font-weight: 300;
		}

		nav.main-nav {
			padding: 20px 20px 0;
			background: #fff;
			text-align: right;
		}

		nav.main-nav a {
			top: 8px;
			right: 6px;
			padding: 8px 12px;
			color: #3070B3;
			font-size: 12px;
			line-height: 1.35;
			border-radius: 3px;
			border: 1px solid #3070B3;
		}

		.contributor {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 14px;
			color: #072140;
			background-color: #fefefe;
		}

		@media only screen and (max-device-width: 420px) {
			.compact {
				width: 100%;
			}
		}

		@media only screen and (min-device-width: 421px) {
			.compact {
				width: 800;
			}
		}
	</style>
	<title>Karnik Ram</title>
</head>

<body>
	<table width="950" border="0" align="center" cellspacing="0" cellpadding="0">
		<tr>
			<td>
				<nav class="main-nav">




					<a href='/blog/'>Blog</a>


				</nav>
			</td>
		</tr>
	</table>
	<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
		<tr>
			<td>
				<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
					<tr>
						<td width="67%" valign="middle">
							<p align="center">
								<name>Karnik Ram</name>
							</p>
							<p align="justify">
								I am an <a href="https://ellis.eu">ELLIS PhD</a> student supervised by Prof. <a href="https://scholar.google.com/citations?user=cXQciMEAAAAJ&hl=en"> Daniel Cremers</a> at the Technical University of Munich
								and Prof. <a href="https://scholar.google.com/citations?user=8200InoAAAAJ&hl=en">Max Welling</a> at the University of Amsterdam. I'm currently interested in physics-based deep learning and its applications in computational chemistry (esp. green applications).
								<br>
								<br>
								Previously, I was a Research Associate in the <a href="https://ri.cmu.edu">Robotics
								Institute</a> at Carnegie Mellon University where I worked 
								with Prof. <a href="http://www.cs.cmu.edu/~srinivas/">Srinivasa Narasimhan</a> on active 3D sensing
								and Prof. <a href="http://www.cs.cmu.edu/~kkitani/">Kris Kitani</a> on indoor navigation.
								<br>
								<br>
								Before that, I was an MS by Research student at <a href="https://iiit.ac.in">IIIT Hyderabad</a>, where I worked on
								improving the robustness of visual-inerital odometry
								algorithms in dynamic environments and other robot perception problems with Prof. <a
									href="https://robotics.iiit.ac.in">K. Madhava
									Krishna</a>. <br>
								<br>
								Even earlier, I was a care-free undergrad working on fun projects at <a
									href="http://www.ssn.edu.in">SSN College of Engineering, Anna University</a>.
							</p>
							<p align="center">
								<a href="mailto:karnikram@gmail.com"
									style="font-weight:normal;color:#3070B3;">Email</a> |
								<a href="/karnik-cv.pdf" style="font-weight:normal;color:#3070B3">CV</a> |
								<a href="https://github.com/karnikram" style="font-weight:normal;color:#3070B3">Github</a> |
								<a href='https://twitter.com/karnikram' style="font-weight:normal;color:#3070B3"> Twitter</a>
							</p>
						</td>
						<td width="33%" id="avatar">
							<img src="/images/karnik-dc.jpg" width="250px">
						</td>
					</tr>
				</table>
			</td>
		</tr>
	</table>

	<table class="compact" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody>
			<tr>
				<td>
					<heading>What's new</heading>
					<ul>
						<li>March 2024: Another old project on robot safety monitoring using programmable lasers is now under review.</li>
						<li>Feb 2024: Our work on improving the training of differentiable bundle adjustment layers (V2V) was accepted for CVPR '24. </li>
						<li>June 2023: My MS thesis at IIIT-H received the <a href="https://alumnifund.iiit.ac.in/giving/endowments/">Ritesh Tiwari Outstanding MS Thesis Award.</a></li>
						<li>April 2023: I will be starting as an <a href="https://ellis.eu">ELLIS PhD</a> student at TUM in Fall '23.</li>
						<li>Oct 2022: Our work on assistive indoor navigation at CMU was featured in <a href="https://www.youtube.com/watch?v=hvfV-iGwYX8&t=4262s">Meta Connect</a>.</li>
						<li>June 2022: Our work on using map priors for inertial odometry was accepted for IROS. </li>
						<li>Oct 2021: I started as a research associate at CMU RI.</li>
						<li>June 2021: Our work on <a href="https://karnikram.info/rp-vio">RP-VIO</a> was accepted
							for IROS. </li>
					</ul>
				</td>
			</tr>
		</tbody>
	</table>


			<table class="compact" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td width="100%" valign="middle">
						<heading>Research</heading>
					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<a href="https://karnikram.info/rp-vio">
							<img src='/images/rpvio.png' style="width:218px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>RP-VIO: Robust Plane-based Visual-Inertial Odometry for Dynamic Environments
							</papertitle>
							</a><br> Karnik Ram, <a href="https://github.com/kharyal">Chaitanya Kharyal</a>, <a
								href="https://github.com/sudarshan-s-harithas">Sudarshan Harithas</a>, <a
								href="https://faculty.iiit.ac.in/~mkrishna/"> K. Madhava Krishna</a>
							<br>
							<i>International Conference on Intelligent Robots and Systems
								(IROS), 2021.</i>

						<p align="justify">We present a monocular visual-inertial odometry (VIO) system that uses only
							planar features and their induced homographies, during both initialization and
							sliding-window estimation, for increased robustness and accuracy in dynamic environments. We
							evaluate on diverse sequences, including our own highly-dynamic simulated dataset, and show
							significant improvement over a state-of-the-art monocular VIO algorithm in dynamic
							environments.</p>
						<a href="https://karnikram.info/rp-vio/">Project page</a>

					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<a href="https://karnikram.info">
							<img src='/images/v2v.png' style="width:218px;height:120px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>
								From Variance to Veracity: Unbundling and Mitigating Gradient Variance in Differentiable Bundle Adjustment Layers
							</papertitle>
							</a><br> <a href="https://swami1995.github.io/">Swaminathan Gurumurthy</a>, Karnik Ram, Bingqing Chen, Zachary Manchester, J Zico Kolter
							<br>
							<i>To appear in CVPR 2024.</i>

						<p align="justify"> Recent work leveraging learning-based optimizers to tightly-couple correspondence estimation
							with a weighted least squares objective have shown SOTA results for various pose estimation tasks, but are still difficult to train.
							We identify possible causes for this instability and propose a simple solution which leads to a 2-2.5x training speedup over a baseline visual odometry model we modify.</p>
						<a href="https://karnikram.info/">Coming soon</a>

					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
			<tr>
					<td width="33%">
						<div style="display:flex;justify-content:center;" >
						<a href="https://www.youtube.com/watch?v=xFZ_9bAb43Q"><img src='/images/plc-safety.png' style="width:180px;height:140"/></a>
						</div>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Robot Safety Monitoring using Programmable Light Curtains</papertitle>
							<br> Karnik Ram, Shobhit Aggarwal, Robert Tamburo, Siddharth Ancha, <a href="https://cs.cmu.edu/~srinivas">Srinivasa Narasimhan </a>
						<p align="justify">
							<br>
							<i>Under review.</i>
							Developed an inexpensive safety monitoring system for industrials robots using <a href="https://www.cs.cmu.edu/~ILIM/light_curtains/">programmable light curtains</a>, a recently developed
							controllable depth sensor. The system enables fence-less human-robot collaboration, is flexible and scales easily to many robots, all without compromising on safety.
						</p>
						<a href="https://cmu-mfi.github.io/plc-safety">Project page</a>
					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<img src='/images/mapprior.png' style="width:238px;height:140px;" />
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Learnable Spatio-Temporal Map Embeddings for Deep Inertial Localization
							</papertitle>
							</a><br> <a href="https://dennismelamed.me/">Dennis Melamed</a>, Karnik Ram, <a
								href="https://vivekroy.com">Vivek Roy</a>, <a href="https://kriskitani.github.io"> Kris
								Kitani</a>
							<br>
							<i> International Conference on Intelligent Robots and Systems
								(IROS),
								2022.</i>

						<p align="justify">We propose a data-driven prior on possible user locations in a map by
							combining learned spatial map embeddings and
							temporal odometry embeddings. Our prior learns to encode which map regions are feasible
							locations for a user more
							accurately than previous hand-defined methods, and leads to a 49% improvement in
							inertial-only localization
							accuracy when used in a particle filter.</p>
						<a href="https://klabcmu.github.io/learned-map-prior">Project page</a>

					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<a href="https://www.youtube.com/watch?v=wDM8EmnzLWI&feature=youtu.be">
							<img src='/images/infer.png' style="width:238px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>INFER: Intermediate Representations for Future Prediction</papertitle>
							</a><br> <a href="https://talsperre.github.io/">Shashank Srikanth</a>, <a
								href="https://junaidcs032.github.io/">Junaid Ahmed Ansari</a>, Karnik Ram, <a
								href="https://scholar.google.com/citations?user=4uKV9aIAAAAJ&hl=en">Sarthak Sharma</a>,
							<a href="http://krrish94.github.io"> J. Krishna Murthy</a>,<a
								href="https://faculty.iiit.ac.in/~mkrishna/"> K. Madhava Krishna</a>
							<br>
							<i>International Conference on Intelligent Robots and Systems
								(IROS), 2019.</i>

						<p align="justify">We have developed an autoregressive model to accurately predict future
							trajectories of traffic participants (vehicles). We demonstrate that using semantics
							provides a significant boost and allows the model generalize to completely different
							datasets, collected across several cities, and also across countries where people drive on
							opposite sides of the road (left-handed vs right-handed driving).</p>
						<a href="https://arxiv.org/abs/1903.10641">Preprint</a> |
						<a href="https://www.youtube.com/watch?v=wDM8EmnzLWI&feature=youtu.be">Video</a>
					</td>
				</tr>
			</table>



			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<a href="https://drive.google.com/open?id=1NekiwKzOZblP-bafRAbHnO72R-1brCEk">
							<img src='/images/calib-pc.png' style="width:238px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle> CalibNet: Geometrically Supervised Extrinsic Calibration using 3D Spatial
								Transformer Networks</papertitle>
							</a><br> <a href="http://epiception.github.io">Ganesh Iyer</a>, Karnik Ram, <a
								href="http://krrish94.github.io"> J. Krishna Murthy</a>,<a
								href="https://faculty.iiit.ac.in/~mkrishna/"> K. Madhava Krishna</a>
							<br>
							<i>International Conference on Intelligent Robots and Systems
								(IROS), 2018.</i>

						<p align="justify">We developed a self-supervised deep network, CalibNet, capable of
							automatically estimating
							the 6-DoF rigid body transformation between a 3D LiDAR and a 2D camera in real-time. The
							network alleviates the need for any calibration targets, thereby reducing
							significant calibration efforts.</p>
						<a href="https://arxiv.org/abs/1803.08181">Preprint</a> |
						<a href="https://drive.google.com/open?id=1NekiwKzOZblP-bafRAbHnO72R-1brCEk">Video</a>
					</td>
				</tr>
			</table>


			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<img src='/images/pathfinder.png' style="width:218px;height:140px;" />
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle> PathFinder: Designing a Map-less Navigation System for Blind People in Unfamiliar Buildings </papertitle>
							<br> 
							<a href="https://www.masakikuribayashi.com/">Masaki Kuribayashi</a>, Tatsuya Ishihara, Daisuke Sato, Jayakorn Vongkulbhisal, Karnik Ram, Seita Kayukawa, Hironobu Takagi, Shigeo Morishima,
							<a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-chiekoa">Chieko Asakawa</a>
							<br>
							<i>ACM CHI Conference on Human Factors in Computing Systems (CHI), 2023.</i>

						<p align="justify">We developed a suitcase robot that allows blind people to find their way around unfamiliar buildings, by detecting and conveying information about intersections and signs.
							We conducted a user study with seven blind participants which showed that the robot improved their ability and confidence in navigating compared to their regular aid.</p>
						<a href="https://drive.google.com/file/d/1sPbwbuiYHWW9CixyshIVQW6FJEiQxBYH/view?usp=sharing">Paper</a> |
						<a href="https://www.youtube.com/watch?v=8bXs0RFx_AA">Presentation</a>
					</td>
				</tr>
			</table>


			<br>
			<table class="compact" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td width="100%" valign="middle">
						<heading>Selected projects</heading>
					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<div style="display:flex;justify-content:center;" >
						<a href="https://drive.google.com/file/d/1Ct_KBYmZsla3RRalO-Ny9TSg3bV9hurB/view?usp=sharing"><img src='/images/navcog2.png' style="width:138px;height:180px;margin-left: auto;margin-right: auto;"/></a>
						</div>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Smartphone-based Indoor Navigation</papertitle><br> Vivek Roy, Karnik Ram, Kris Kitani &nbsp;|&nbsp; Summer
							2022
						<p align="justify">
							Developed a turn-by-turn assistive indoor navigation app for iOS that combined three deep models for localization in real-time
							-- LSTM for bluetooth-based absolute position estimation, LSTM for IMU-based relative position estimation, LSTM + U-Net for
							encoding floor map information. Data collected using <a href="https://about.meta.com/realitylabs/projectaria/">Meta's Project Aria Glasses</a> were used for training the models.
						</p>
						<a href="https://drive.google.com/file/d/1Ct_KBYmZsla3RRalO-Ny9TSg3bV9hurB/view?usp=sharing">Video demo</a> |
						<a href="https://drive.google.com/file/d/1dgYrTZKwIKybhzXyjdfPwOmABQXiCRs9/view?usp=sharing">Presentation</a> |
						<a href="https://www.youtube.com/watch?v=hvfV-iGwYX8&t=4262s"> <span style='font-weight:normal;color:#3070B3;'>Meta Connect feature</style> </a>
					</td>
				</tr>
				<tr>
					<td width="33%">
						<a href="https://www.youtube.com/watch?v=IWMdQcNshFI">
							<img src='/images/week-13.png' style="width:238px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Automatic Calibration of Sensor Extrinsics</papertitle><br> Karnik Ram
							&nbsp;|&nbsp; Summer
							2018
						<p align="justify">
							An end-to-end application with a graphical user interface for easily calibrating the
							extrinsics between range and visual sensors was developed during GSoC 2018. Automatic and
							target-less calibration algorithms based on plane-matching and line-matching were integrated
							into the app, allowing the calibration to be performed in any generic scene setting without
							the need for any specific targets.
						</p>
						<a href="https://github.com/karnikram/autocalib-sensor-extrinsics">Code</a> |
						<a href="https://www.youtube.com/watch?v=IWMdQcNshFI">Video demo</a> |
						<a href="http://karnikram.info/blog/gsoc-2018-progress/">Report</a>
					</td>
				</tr>

				<tr>
					<td width="33%">
						<img src='/images/artpark.png' style="width:238px;height:140px;" />
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>ARTPARK Robotics Challenge</papertitle><br> Suraj Bonagiri, Viswanarayanan S,
							Sreeharsha P, Ashwin Rao, Karnik Ram &nbsp;|&nbsp; Summer
							2021
						<p align="justify">
							Mentored and worked with a team in a national-level competition on a janitorial robot to autonomously
							navigate and clean a washroom setup. The team was selected for the simulation and on-site rounds out of
							of 136 teams and finished second overall. 
						</p>
						<a href="https://www.artpark.in/robotChallenge">Challenge page</a>
					</td>
				</tr>
			<!--</table>

			<br><br>
			<table class="compact" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td width="100%" valign="middle">
						<heading>Undergrad Projects</heading>
					</td>
				</tr>
			</table>

			<table class="compact" border="0" align="center" cellspacing="0" cellpadding="20">
				<tr>
					<td width="33%">
						<a href="/images/residual.png">
							<img src='/images/residual.png' style="width:238px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Direct Dense Image Registration</papertitle><br> Karnik Ram,<a
								href="http://krrish94.github.io/"> J. Krishna Murthy</a> &nbsp;|&nbsp; Fall
							2017
						<p align="justify">
							Estimated the camera motion between two frames by minimizing the photometric error between
							them. Implemented in matlab using a vanilla Levenberg-Marquardt non-linear least squares
							(approx.) solver.
						</p>
						<a href="/papers/image-registration.pdf">Results</a>
					</td>
				</tr>

				<tr>
					<td width="33%">
						<a href="/images/motion-calib.png">
							<img src='/images/motion-calib.png' style="width:238px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Motion-based Camera-IMU Extrinsic Calibration</papertitle><br> Karnik Ram,<a
								href="https://www.linkedin.com/in/https://www.linkedin.com/in/kunal-chelani-25550657/">
								Kunal Chelani</a> &nbsp;|&nbsp; Fall

							2017
						<p align="justify">
							Implemented a pipeline to estimate the rigid body pose between an IMU and a camera by
							applying the Kabsch algorithm to their motion estimates. Based on Zachary Taylor and Juan
							Nieto's work on Motion-Based Calibration of Multimodal Sensor Arrays.
						</p>
						<a href="/papers/motion-calib.pdf">Report</a> |
						<a href="https://github.com/karnikram/motion-calib">Code</a>

					</td>
				</tr>-->

				<tr>
					<td width="33%">
						<a href="/images/stockcounting.jpg">
							<img src='/images/stockcounting.jpg' style="width:238px;height:140px;" />
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Automated Stock Counting Using a Quadcopter</papertitle><br> Karnik Ram,<a
								href="https://www.linkedin.com/in/harishsampathkumar/"> Harish S</a>, <a
								href="https://www.linkedin.com/in/apeksha-avinash/"> Apeksha Avinash</a> &nbsp;|&nbsp;
							Winter
							2016
						<p align="justify">
							Developed a visual odometry module based on optic flow for the localization of a
							custom-built quadcopter and incorporated
							it into the PX4 navigation stack, enabling autonomous indoor navigation. All the
							computations were performed on-board,
							on an Odroid XU4. A stock counting module was implemented using ArUco markers.
						</p>
						<a href="/papers/syp-report.pdf">Report</a> |
						<a href="https://github.com/karnikram/opticflow_odometry">Code</a>
					</td>
				</tr>

				<!--<tr>
					<td width="33%">
						<a href="/images/motioncap.png">
							<img src='/images/motioncap.png' style="width:238px;height:140px;">
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Motion Capture using a Kinect</papertitle><br> Karnik Ram &nbsp;|&nbsp; Fall
							2016
						<p align="justify">Used SimpleOpenNI to track body joint angles and mapped it to a model in
							blender. This was developed as a part of a
							body posture tracking project during my time as an intern at <a
								href="https://htic.iitm.ac.in">HTIC</a>.</p>
						<a href="https://github.com/karnikram/kinect-motioncapture">Code</a> |
						<a href="https://youtu.be/6r8AaOC6phs">Video</a>
					</td>
				</tr>

				<tr>
					<td width="33%">
						<a href="/images/navstik.png">
							<img src='/images/navstik.png' style="width:238px;height:140px;">
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Person Tracking for a Drone</papertitle><br> Karnik Ram &nbsp;|&nbsp; Summer
							2016
						<p align="justify">Developed and evaluated a person tracking application for a drone using a
							CUDA accelerated monocular HOG detector, and
							another using disparity maps generated from a custom stereo rig. Both were tested on a
							Jetson TX1. This was developed
							during my time as an intern at <a href="https://navstik.org">Navstik Labs.</a></p>
					</td>
				</tr>

				<tr>
					<td width="25%">
						<div style="height:140px;width:238px;display:flex;justify-content:center;margin-top:0.25cm" />
						<a href="/images/visualservoing-large.jpg">
							<img src='/images/visualservoing.jpg' style="width:120px;height:120px;">
						</a>
						</div>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Visual Servoing of a Mobile Robot</papertitle><br> Karnik Ram, Yash Oza
							&nbsp;|&nbsp; Spring 2016
						<p align="justify">Developed a simple navigation stack for controlling the motion of a
							differential drive mobile robot using visual feed-back
							from an overhead camera. The stack consisted of a color based localization module and a PID
							controller for issuing
							steering commands to the motors.</p>
						<a href="https://github.com/karnikram/visual-servoing">Code</a> |
						<a href="https://youtu.be/kU-pIHazJII">Video</a>
					</td>
				</tr>

				<tr>
					<td width="25%">
						<a href="/images/flightcontroller.jpg">
							<img src='/images/flightcontroller.jpg' style="width:238px;height:140px;">
						</a>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Low-Cost Flight Controller for a Quadcopter</papertitle><br> Karnik Ram, Harish
							S, Aadithya V, Ashwin V, Harshwardhan &nbsp;|&nbsp;
							Fall 2015
						<p align="justify">
							Built and programmed a flight controller for stabilizing a custom built quadcopter, using
							the ATmega328. Utilized interrupt
							service routines, I2C comm, PWM and PID rate control loops.
						</p>
						<a href="https://github.com/karnikram/ssn-copter">Code</a>
					</td>
				</tr>

				<tr>
					<td width="25%">
						<div style="height:140px;width:238px;display:flex;justify-content:center;margin-top:0.25cm" />
						<a href="https:github.com/karnikram/seglio">
							<img src='/images/seglio.png' style="width:140px;height:140px;">
						</a>
						</div>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>Seglio</papertitle><br> Karnik Ram, Shankar S, Prashanth TV &nbsp;|&nbsp; Summer
							2015
						<p align="justify">Developed an Android app that enabled students to share their course
							textbooks among each other easily. This app has got close
							to a thousand installations and has also been featured in a prominent weekly magazine, and
							in the top 10 of the Apps for Chennai contest.
						</p>
						<a href="https://github.com/karnikram/seglio">Code</a> |
						<a href="https://goo.gl/2pN1YK">Store</a> |
						<a
							href="http://www.thehindu.com/features/downtown/students-engineer-an-innovation/article7386620.ece"><span style='font-weight:normal;color:#3070B3;'>Press</span></a>
						|
						<a
							href="http://www.thehindu.com/news/cities/chennai/food-travel-and-books-all-via-apps/article7740797.ece">Press</a><br>
					</td>
				</tr>-->

				<tr>
					<td width="25%">
						<div style="height:140px;width:238px;display:flex;justify-content:center;margin-top:0.25cm" />
						<a href="http://github.com/karnikram/the-ssn-app">
							<img src='/images/ssnapp.png' style="width:140px;height:130px;">
						</a>
						</div>
					</td>
					<td valign="top" width="67%">
						<p>
							<papertitle>The SSN App</papertitle><br> Karnik Ram, Adithya J, Varun R, Muthu CT
							&nbsp;|&nbsp; Winter 2014
						<p align="justify">
							Ideated and developed an Android application to notify students and faculty about important
							events, announcements and other
							campus related information like bus routes and dining menus. It has close to two thousand
							users today and is the official
							app of SSN.
						</p>
						<a href="https://github.com/karnikram/the-ssn-app">Code</a> |
						<a href="https://play.google.com/store/apps/details?id=in.edu.ssn.ssnapp">Store</a> |
						<a href="/images/shivnadar.jpg"><span style='font-weight:normal;color:#3070B3;'>Appreciation</span></a> |
						<a href="http://www.thehindu.com/features/downtown/students-engineer-an-innovation/article7386620.ece"><span style='font-weight:normal;color:#3070B3;'>Press</span></a>
					</td>
				</tr>

			</table>

			<br><br>
			<table class="compact" align="center" border="0" cellspacing="0" cellpadding="20">
				<tbody>
					<tr>
						<td>
							<heading>Blog</heading>
							<ul>
								<li> <a href="https://karnikram.info/blog/train-trip">My cross-US train trip</a></li>
								<li> <a href="https://karnikram.info/blog/notes-setup">My note-taking setup</a></li>
								<li> <a href="https://karnikram.info/blog/node-setup">Setting up a server node</a></li>
								<li> <a href="https://karnikram.info/blog/ethrss">ETH Robotics Summer School</a></li>
								<li> <a href="https://karnikram.info/blog/gsoc-2018-progress">Google Summer of Code with
										MRPT</a></li>
								<li> <a href="https://karnikram.info/blog/lie">Lie Groups and Lie Algebra</a></li>
							</ul>
						</td>
					</tr>
				</tbody>
			</table>

					<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
						<tr>
							<td>
								<br>
								<p align="right">
									<font size="3">
										Built using <a href="http://gohugo.io">Hugo </a>and <a
											href="http://jonbarron.info">Jon's</a> styling</a>
										<br>
									        <span style='font-weight:normal;'>Profile picture courtesy: <a href="https://nnsriram97.github.io/">Sriram</a></span>
									        <br>
										<span style='font-weight:normal;color:#3070B3;'>Last updated: March, 2024</span>
									</font>
								</p>
							</td>
						</tr>
					</table>
</body>

</html>
